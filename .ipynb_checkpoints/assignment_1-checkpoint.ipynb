{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE954 : Deep Learning Fundamentals\n",
    "### Assignment 1\n",
    "\n",
    "**Group Number:** 12  \n",
    "**Team Members:**  \n",
    "- Lokesh  (Roll No: 241562482)  \n",
    "- Akshay (Roll No: _____)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries &#8595;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download and Split &#8595;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset copied successfully to: /Users/lokeshkumar/eMasters/EE954_Deep_Learning/Assignments/../datasets\n",
      "Contents:\n",
      " - t10k-images-idx3-ubyte\n",
      " - fashion-mnist_test.csv\n",
      " - t10k-labels-idx1-ubyte\n",
      " - train-images-idx3-ubyte\n",
      " - fashion-mnist_train.csv\n",
      " - train-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "# where the MNIST data will be saved permanently\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"..\", \"datasets\")\n",
    "\n",
    "# Download dataset to the default directory\n",
    "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "\n",
    "# Copy the downloaded the dataset to the desired path\n",
    "shutil.copytree(path, DATA_DIR, dirs_exist_ok=True)\n",
    "\n",
    "if os.path.exists(DATA_DIR) and os.listdir(DATA_DIR):\n",
    "    print(f\"Dataset copied successfully to: {DATA_DIR}\")\n",
    "    print(\"Contents:\")\n",
    "    for f in os.listdir(DATA_DIR):\n",
    "        print(\" -\", f)\n",
    "else:\n",
    "    print(\"Dataset folder is missing or empty!\")\n",
    "\n",
    "train_file = os.path.join(DATA_DIR, \"fashion-mnist_train.csv\")\n",
    "test_file = os.path.join(DATA_DIR, \"fashion-mnist_test.csv\")\n",
    "\n",
    "df = pd.read_csv(train_file)\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data Preprocessing (3 Marks)\n",
    "• Define a preprocess function to preprocess the images. (The function should have\n",
    "the same name).\n",
    "• The function should flatten the images.\n",
    "• The function should also normalize the pixel values to the range [0, 1]. Depending\n",
    "on how you have implemented the code so far, the pixel values might already be\n",
    "normalized to this range. However, for clarity and completeness, include an explicit\n",
    "normalization step regardless. &#8595;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_(X):\n",
    "    if X.ndim == 3:\n",
    "        X = X.reshape(X.shape[0], -1)   # Flatten each image\n",
    "    if X.max() > 1:\n",
    "        X = X / 255.0                  # Normalize\n",
    "    return X\n",
    "\n",
    "\n",
    "class PreprocessedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "  \n",
    "    def preprocess(self):\n",
    "        return preprocess_(self.dataset)  # Apply preprocessing\n",
    "\n",
    "\n",
    "# Wrap your existing datasets\n",
    "X_train = PreprocessedDataset(X_train)\n",
    "X_val = PreprocessedDataset(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Activation Function &#8595;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(activation_type, z):\n",
    "    if activation_type == 'relu':\n",
    "        return np.maximum(0, z)\n",
    "    if activation_type == 'sigmoid':\n",
    "        return 1/(1+np.exp(-z))\n",
    "    if activation_type == 'tanh':\n",
    "        return (np.tanh(z))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported activation type. Use 'relu', 'sigmoid', or 'tanh'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation  &#8595;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "X dataframe shape(60000, 784)\n",
      "y dataframe shape(60000,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "#Total number of classes to be predicted\n",
    "n_classes = len(np.unique(y))\n",
    "print(n_classes)\n",
    "\n",
    "print(f\"X dataframe shape{X.shape}\")\n",
    "print(f\"y dataframe shape{y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Propagation  &#8595;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(self, PreprocessedDataset):\n",
    "    def init __super():\n",
    "        self.PreprocessedDataset\n",
    "    init __self__():\n",
    "   \n",
    "    X_train = preprocess(X_train)\n",
    "    X_val = preprocess(X_val)\n",
    "\n",
    "nn = MLP()\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    nn.forwardpropagation()\n",
    "    nn.backpropagation()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
